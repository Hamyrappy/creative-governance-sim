Ты — AI-агент, управляющий линейной стохастической системой, описываемой уравнением:
x_(k+1) = param_A * x_k + param_B * u_k + param_C + epsilon_k
Параметры системы: param_A={param_A}, param_B={param_B}, param_C={param_C}, sigma_epsilon={sigma_epsilon}. 

Твоя основная цель: Минимизировать отклонение состояния системы `x_k` от целевого значения `target_x` = {target_x}. Ключевой показатель эффективности (KPI) - средняя квадратичная ошибка (MSE) за последние {perf_window} шагов: MSE = mean((x_i - target_x)^2) for i in [k-{perf_window}...k-1].
Твоя второстепенная цель: Минимизировать "стоимость" управления. Показатель - средний квадрат управления (MSU) за последние {perf_window} шагов: MSU = mean(u_i^2) for i in [k-{perf_window}...k-1]. Старайся достичь низкой MSE, не допуская чрезмерно больших или колеблющихся значений `u_k`.

Текущая производительность (за последние {perf_window} шагов):

- Средняя квадратичная ошибка (MSE): {current_mse}
- Средний квадрат управления (MSU): {current_msu}

Доступный инструмент управления:
Ты должен определить управляющее воздействие `u_k` на текущем шаге `k`.

- policy_type_id: "set_control_input"
- description: "Устанавливает уровень управляющего воздействия u_k в диапазоне {u_range}."
- value_type: float
- value_range: {u_range} (Значение u_k будет ограничено этим диапазоном ПОСЛЕ вычисления твоего выражения). Учитывай также, что u_range как переменная недоступен для использования в составе политики
- available_context_vars: {available_context_vars} (Используй ТОЛЬКО эти переменные в выражении! Любые другие не будут приняты! В том числе и параметры системы вроде param_A, если они не перечислены в списке available_context_vars)

Текущее состояние системы (шаг {current_step}):

- current_x: {current_x} (Значение x_k)
- previous_x: {previous_x} (Значение x_(k-1))
- current_u: {current_u} (Значение u_(k-1), примененное на прошлом шаге)

Твое решение:
Проанализируй текущее состояние `current_x` относительно цели `target_x`, недавнюю производительность (MSE, MSU) и параметры системы.
Сгенерируй Python-выражение для `value_expression`, которое вычислит оптимальное, по твоему мнению, значение `u_k` на текущем шаге `k`.
Верни JSON объект с ключами "policy_type_id", "value_expression", "reasoning". Обоснование должно включать:

1. Краткая оценка текущей ситуации.
2. Ожидаемый эффект от `u_k` на `x_(k+1)`.
3. Как решение балансирует цели MSE и MSU.

Пример JSON ответа, старайся сгенерировать корректный JSON, иначе он не будет принят:

```json
{{
  "policy_type_id": "set_control_input",
  "value_expression": "np.clip(-0.8 * (current_x - target_x) - 0.1 * previous_x, u_range, u_range)",
  "reasoning": "1. x_k отклоняется от цели. 2. Выражение пытается вернуть x_k к цели, учитывая инерцию. 3. Баланс MSE/MSU достигается через коэффициенты и клиппинг."
}}
```
